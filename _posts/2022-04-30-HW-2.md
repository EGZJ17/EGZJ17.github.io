---
layout: post
title: "Movie and Tv Show Recomendations"
---

*In this blog post, I will be using the Scrapy Python package to extract data from the IMDB website. I will build a simple recommendation system that will recommend movies or TV shows based on the number of actors a title shares with my favorite TV show, Friends.*

# §1. Setup
## §1.1 Locate the Starting IMDB Page

Pick your favorite movie or TV show, and locate its IMDB page. For example, my favorite TV show is Friends. Its IMDB page is at:
```
https://www.imdb.com/title/tt0108778/
```
Save this URL for a moment.

## §1.2 Here's how we set up your scrapy project
1. Create a new GitHub repository, and sync it with GitHub Desktop. This repository will house your scraper. **You should commit and push each time you make significant changes to your code.**
Here’s a link to my project repository
```
https://github.com/EGZJ17/IMDB-Scrapy-
```
2. Open a terminal in the location of your repository on your laptop, and type: 
```
conda activate PIC16B
scrapy startproject IMDB_scraper
cd IMDB_scraper
```
This will create quite a lot of files, but you don't really need to touch most of them.

# §2. Write Your Scraper

Create a file inside the `spiders` directory called `imdb_spider.py`. Add the following lines to the file: 

```python
import scrapy

class ImdbSpider(scrapy.Spider):
    name = 'imdb_spider'
    
    start_urls = ['hhttps://www.imdb.com/title/tt0108778/']
```
Replace the entry of `start_urls` with the URL corresponding to your favorite movie or TV show. 

## 2.1 Now, implement three parsing methods for the `ImdbSpider` class.

1. **parse(self, response)**
``` python
def parse(self,response):
        '''
        A parsing method that navigates to its Cast and Crew page.
        '''
        # Join current url with "fullcredits"
        full_credits = response.urljoin("fullcredits")
        yield scrapy.Request(full_credits, callback = self.parse_full_credits)
```
This method works by starting on a movie or TV show's home page, and then navigates to the Cast & Crew page. Once arrived at the full credits page, a second function, `parse_full_credits(self,response)`, is called in the `callback` argument of `scrapy.Request`.

2. **parse_full_credits(self, response)**
``` python
def parse_full_credits(self,response):
        '''
        A parsing method that navigates to each actor's page
        '''
        # a list to get all urls to each actor's IMDB page
        actor_page_list = [a.attrib["href"] for a in response.css("td.primary_photo a")]

        # navigate to each actor's IMDB page
        for next_page in actor_page_list:
            next_page = response.urljoin(next_page)
            yield scrapy.Request(next_page, callback = self.parse_actor_page)
```
In this method, we start on the Cast & Crew page and try to navigate through each actor's page. The above list comprehension will create a list of relative paths, one for each actor. To find the url to the actor pages, we can make use of the web developer tool: 
![Primary-Photo.png](/images/Primary-Photo.png)
We see the url to the actor page is the `"href"` attribute in `a` in the element `"td.primary_photo a"`. This information can be extracted using `response.css`. Once arrived at the actor's page, the third function `parse_actor_page(self, response)` is called, again in the `callback` argument of `scrapy.Request`.

3. **parse_actor_page()**
``` python
def parse_actor_page(self, response):
        '''
        A parsing method to get all movies and TV shows that an actor
        is listed in and put in dictionary.
        '''
        #get actor name
        actor_name = response.css("h1.header").css("span.itemprop::text").get()

        # use set to avoid multiple entries
        movie_or_TV_list = set([a.get() for a in response.css("div.filmo-row b").css("a::text")])
        
        #yield dictionary
        for a in movie_or_TV_list:
            movie_or_TV_name = a
            yield {"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}
```
To write this method, we start on the page of the actor. This method yields a dictionary with two key-value pairs, of the form `{"actor" : actor_name, "movie_or_TV_name" : movie_or_TV_name}`. The method yields one such dictionary for each of the movies or TV shows on which that actor has worked. To get the actor's name and what they worked on, we need the web developer tool: 
![actor_name.png](/images/actor_name.png)
We see the `actor_name` is in the class `"h1.header span.itemprop"`
![Movie-tv.png](/images/Movie-tv.png)
We see the `movie_or_TV_name` is in `"div.filmo-row b a"` element.

We use the `.get()` method since they both contain text information. We use `set()` to avoid multiple entries when the actors also are apart of movies or tv shows as other occupations besides acting, such as directing or producing. The we yield our desired dictionary. 

Now, you can run the command 
```bash
scrapy crawl imdb_spider -o results.csv
```
to create a `.csv` file with a column for actors and a column for movies or TV shows. 
